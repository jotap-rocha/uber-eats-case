# Pipeline de Dados Uber Eats â€” Portfolio

Pipeline completo de engenharia de dados construido como portfolio profissional, simulando um ambiente de producao de um aplicativo de delivery (Uber Eats). O projeto implementa as melhores praticas de Data Engineering Moderna: arquitetura local automatizada (Docker + PowerShell), ingestao com Airbyte, processamento no Databricks Lakehouse com Delta Live Tables, Arquitetura Medalhao (Bronze â†’ Silver â†’ Gold), governanca com Unity Catalog e consumo em Power BI / Databricks AI/BI Genie.

---

## Arquitetura (alto nÃ­vel)

- Fontes: PostgreSQL (OLTP) e MinIO (Data Lake).
- IngestÃ£o: Airbyte para extrair e carregar os dados.
- Processamento: Databricks Lakehouse como plataforma central.
- TransformaÃ§Ã£o: Arquitetura MedalhÃ£o (Bronze â†’ Silver â†’ Gold).
- GovernanÃ§a: Unity Catalog (qualidade, linhagem e seguranÃ§a).
- Consumo: Power BI e Databricks AI/BI Genie.

---

## Requisitos de Hardware

### Minimos Recomendados

- **CPU**: Intel Core i5 8Âª geracao ou equivalente (4 cores)
- **RAM**: 16 GB (20 GB recomendado)
- **Armazenamento**: 50 GB livres (SSD preferencial)
- **Sistema Operacional**: Windows 10/11

---

## Pre-requisitos de Software

- Windows 10/11 com Docker Desktop instalado e em execucao
- PowerShell 5.1+ (padrao do Windows) ou PowerShell 7+ (`pwsh`)
- Acesso a internet para baixar imagens Docker
- Workspace Databricks com Unity Catalog (opcional, para proximas etapas)
- Licenca ShadowTraffic Free Trial (https://shadowtraffic.io)

---

## Como ComeÃ§ar

### Passo 1: Configurar Credenciais

Antes de provisionar o ambiente, vocÃª precisa configurar as credenciais em dois arquivos:

#### A) Credenciais do Docker Compose (raiz do projeto)

1. **Copie o template**:
```powershell
copy .env.template .env
```

2. **Edite o arquivo `.env`** e preencha suas credenciais:
```powershell
notepad .env
```

**VariÃ¡veis principais**:
```ini
# PostgreSQL
POSTGRES_USER=<seu_usuario>
POSTGRES_PASSWORD=<sua_senha>
POSTGRES_DB=ubereats_db

# MinIO
MINIO_ROOT_USER=<seu_usuario>
MINIO_ROOT_PASSWORD=<sua_senha>
```

#### B) Credenciais do ShadowTraffic (pasta `gen/`)

1. **Copie o template**:
```powershell
copy gen\.env.template gen\.env
```

2. **Edite o arquivo `gen/.env`** e preencha as variÃ¡veis:
```powershell
notepad gen\.env
```

**VariÃ¡veis principais**:

```ini
# PostgreSQL (defina seu usuÃ¡rio e senha)
POSTGRES_HOST=postgres-ubereats
POSTGRES_PORT=5432
POSTGRES_DB=ubereats_db
POSTGRES_USERNAME=<seu_usuario>
POSTGRES_PASSWORD=<sua_senha>

# MinIO (defina seu usuÃ¡rio e senha)
AWS_REGION=us-east-1
AWS_S3_FORCE_PATH_STYLE=true
AWS_ACCESS_KEY_ID=<seu_usuario>
AWS_SECRET_ACCESS_KEY=<sua_senha>

# ShadowTraffic (obtenha em https://shadowtraffic.io)
LICENSE_ID=<seu_license_id>
LICENSE_KEY=<sua_license_key>
LICENSE_EMAIL=<seu_email>
LICENSE_OWNER=<seu_nome>
```

3. **Gere os arquivos de configuraÃ§Ã£o** (opcional, o `start-all.ps1` faz isso automaticamente):
```powershell
powershell -ExecutionPolicy Bypass -File .\gen\setup-configs.ps1
```

---

### Passo 2: Provisionar o Ambiente (Pasta `docs/`)

ApÃ³s configurar as credenciais, consulte a **documentaÃ§Ã£o completa** em `docs/` para provisionar cada componente:

ğŸ“š **[Acesse a documentaÃ§Ã£o completa aqui: docs/README.md](docs/README.md)**

**Ordem recomendada**:
1. [docs/automacao/README.md](docs/automacao/README.md) - Scripts de automaÃ§Ã£o e Docker Compose
2. [docs/postgres/README.md](docs/postgres/README.md) - PostgreSQL (banco OLTP)
3. [docs/minio/README.md](docs/minio/README.md) - MinIO (Data Lake)
4. [docs/shadowtraffic/README.md](docs/shadowtraffic/README.md) - ShadowTraffic (gerador de dados)
5. [docs/airbyte/README.md](docs/airbyte/README.md) - Airbyte (ingestÃ£o de dados)

**Inicio rÃ¡pido**:
```powershell
# Inicia toda a infraestrutura + geradores de dados
.\scripts\start-all.ps1

# Verifica o status
docker-compose ps
```

---

## Estrutura do Projeto

```
.
â”œâ”€â”€ gen/                    # âš™ï¸ ConfiguraÃ§Ãµes e credenciais
â”‚   â”œâ”€â”€ .env               # Suas credenciais (CONFIGURE PRIMEIRO!)
â”‚   â”œâ”€â”€ .env.template      # Template de exemplo
â”‚   â”œâ”€â”€ setup-configs.ps1  # Script de injeÃ§Ã£o de secrets
â”‚   â”œâ”€â”€ postgres/          # Configs ShadowTraffic para Postgres
â”‚   â””â”€â”€ minio/             # Configs ShadowTraffic para MinIO
â”œâ”€â”€ docs/                   # ğŸ“š DocumentaÃ§Ã£o tÃ©cnica completa
â”‚   â”œâ”€â”€ README.md          # Ãndice da documentaÃ§Ã£o
â”‚   â”œâ”€â”€ automacao/         # Scripts PowerShell e Docker Compose
â”‚   â”œâ”€â”€ postgres/          # PostgreSQL
â”‚   â”œâ”€â”€ minio/             # MinIO
â”‚   â”œâ”€â”€ shadowtraffic/     # ShadowTraffic
â”‚   â””â”€â”€ airbyte/           # Airbyte
â”œâ”€â”€ scripts/                # ğŸ¤– Scripts de automaÃ§Ã£o
â”‚   â”œâ”€â”€ start-all.ps1      # Inicia tudo
â”‚   â”œâ”€â”€ start-infra.ps1    # Apenas infra
â”‚   â”œâ”€â”€ start-generators.ps1 # Apenas geradores
â”‚   â”œâ”€â”€ stop-all.ps1       # Para tudo
â”‚   â””â”€â”€ reset-all.ps1      # Reset destrutivo
â”œâ”€â”€ sql/                    # ğŸ“Š Scripts SQL (DDL, CDC)
â”œâ”€â”€ pipeline/               # ğŸ”„ Scripts Databricks (Delta Live Tables)
â”‚   â””â”€â”€ README.md          # Pipelines Lakeflow (em desenvolvimento)
â”œâ”€â”€ docker-compose.yml      # OrquestraÃ§Ã£o Docker
â””â”€â”€ README.md              # Este arquivo
```

---

## Dados Gerados

O ambiente atual possui:
- **111.348 registros** na tabela `drivers`
- **111.155 registros** na tabela `users`
- **20+ streams de eventos JSON** no bucket MinIO `uber-eats` (orders, gps, payments, etc.)

---

## Status do Projeto

### âœ… ConcluÃ­do

- [x] Infraestrutura local (Docker + PostgreSQL + MinIO)
- [x] GeraÃ§Ã£o de dados sintÃ©ticos (ShadowTraffic)
- [x] Scripts de automaÃ§Ã£o (PowerShell)
- [x] ConfiguraÃ§Ã£o de ingestÃ£o (Airbyte OSS)
- [x] DocumentaÃ§Ã£o tÃ©cnica completa

### ğŸš§ Em Desenvolvimento

- [ ] Pipelines Databricks (Delta Live Tables)
  - Camada Bronze (Auto Loader + CDC)
  - Camada Silver (Limpeza e transformaÃ§Ã£o)
  - Camada Gold (AgregaÃ§Ãµes e mÃ©tricas)
- [ ] GovernanÃ§a (Unity Catalog)
- [ ] Dashboards (Power BI / Databricks AI/BI Genie)

**PrÃ³xima etapa**: Os scripts de processamento de dados no Databricks serÃ£o desenvolvidos e armazenados na pasta `pipeline/`. Esses scripts serÃ£o anexados ao **Lakeflow (Delta Live Tables)** para implementar a Arquitetura MedalhÃ£o.

---

## Acessos RÃ¡pidos

### URLs
- MinIO Console: `http://localhost:9001`
- Airbyte Console: `http://localhost:8000`

### Postgres
- Host: `localhost`
- Port: `5432`
- Database/User/Password: Conforme seu `gen/.env`

### MinIO
- Console: `http://localhost:9001`
- API: `http://localhost:9000`
- User/Password: Conforme seu `gen/.env`
- Bucket: `uber-eats`

---

## Comandos RÃ¡pidos

```powershell
# Iniciar ambiente completo
.\scripts\start-all.ps1

# Apenas infraestrutura (sem geradores)
.\scripts\start-infra.ps1

# Verificar status
docker-compose ps

# Parar tudo (preserva dados)
.\scripts\stop-all.ps1

# Reset completo (APAGA DADOS!)
.\scripts\reset-all.ps1
```

---

## Troubleshooting

Para problemas especÃ­ficos, consulte a documentaÃ§Ã£o de cada componente em `docs/`:

- Scripts e automaÃ§Ã£o: [docs/automacao/README.md](docs/automacao/README.md)
- PostgreSQL: [docs/postgres/README.md](docs/postgres/README.md)
- MinIO: [docs/minio/README.md](docs/minio/README.md)
- ShadowTraffic: [docs/shadowtraffic/README.md](docs/shadowtraffic/README.md)
- Airbyte: [docs/airbyte/README.md](docs/airbyte/README.md)

---

## Suporte e Contribuicoes

- **Documentacao Completa**: Veja a pasta `docs/` para detalhes tecnicos de cada componente
- **Issues**: Relate problemas via [GitHub Issues](https://github.com/jotap-rocha/uber-eats-case/issues)
- **Repositorio**: https://github.com/jotap-rocha/uber-eats-case

---

Pronto! Com isso voce tem uma fabrica de dados local completa para testes de pipelines, CDC e integracoes, com dados sinteticos realistas.
