# Pipeline Databricks - Delta Live Tables (Lakeflow)

Scripts de processamento de dados para o Databricks Lakehouse utilizando Delta Live Tables (DLT) no Lakeflow.

---

## Visao Geral

Esta pasta contÃ©m os scripts Python/SQL que implementam a **Arquitetura MedalhÃ£o** no Databricks:

```
Bronze Layer â†’ Silver Layer â†’ Gold Layer
(Raw)         (Cleaned)       (Aggregated)
```

Os scripts serÃ£o anexados ao **Lakeflow (Delta Live Tables)** para criar pipelines de transformaÃ§Ã£o com:
- **Auto Loader**: IngestÃ£o incremental de dados
- **CDC (Change Data Capture)**: Captura de mudanÃ§as do PostgreSQL
- **Expectations**: Qualidade de dados
- **Unity Catalog**: GovernanÃ§a e linhagem

---

## Estrutura Planejada

```
pipeline/
â”œâ”€â”€ bronze/
â”‚   â”œâ”€â”€ bronze_drivers.py       # IngestÃ£o de drivers (CDC)
â”‚   â”œâ”€â”€ bronze_users.py         # IngestÃ£o de users (CDC)
â”‚   â””â”€â”€ bronze_events.py        # IngestÃ£o de eventos JSON (Auto Loader)
â”œâ”€â”€ silver/
â”‚   â”œâ”€â”€ silver_drivers.py       # Limpeza e transformaÃ§Ã£o
â”‚   â”œâ”€â”€ silver_users.py         # Limpeza e transformaÃ§Ã£o
â”‚   â””â”€â”€ silver_orders.py        # Flatten de JSONs + enriquecimento
â””â”€â”€ gold/
    â”œâ”€â”€ gold_kpis.py            # MÃ©tricas de negÃ³cio
    â”œâ”€â”€ gold_driver_stats.py    # EstatÃ­sticas de motoristas
    â””â”€â”€ gold_user_behavior.py   # Comportamento de usuÃ¡rios
```

---

## Status

ðŸš§ **Em desenvolvimento**

Os scripts serÃ£o desenvolvidos seguindo a documentaÃ§Ã£o em:
- `.claude/kb/how_construct_dlt.md` - Tutorial DLT, CDC e Auto Loader
- `.claude/kb/project_architecture.md` - Arquitetura end-to-end

---

## Como Usar (Futuro)

### 1. Anexar Scripts no Lakeflow

1. Acesse o Databricks Workspace
2. Navegue atÃ© **Lakeflow (Delta Live Tables)**
3. Crie um novo pipeline
4. Anexe os scripts desta pasta
5. Configure:
   - **Target**: `main.uber_eats`
   - **Storage**: External Location no Unity Catalog
   - **Cluster**: Serverless (recomendado)

### 2. Executar Pipeline

```python
# Via Databricks CLI (futuro)
databricks pipelines create --settings pipeline-config.json
databricks pipelines start --pipeline-id <id>
```

---

## ReferÃªncias

- Delta Live Tables: https://docs.databricks.com/delta-live-tables/
- Auto Loader: https://docs.databricks.com/ingestion/auto-loader/
- Unity Catalog: https://docs.databricks.com/data-governance/unity-catalog/
- Arquitetura MedalhÃ£o: https://www.databricks.com/glossary/medallion-architecture

---

## Proximos Passos

1. Desenvolver scripts Bronze (ingestÃ£o)
2. Desenvolver scripts Silver (transformaÃ§Ã£o)
3. Desenvolver scripts Gold (agregaÃ§Ã£o)
4. Criar configuraÃ§Ã£o de pipeline (JSON)
5. Testar no Databricks Community
6. Documentar expectations e testes de qualidade

