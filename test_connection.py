# Test de conexÃ£o com Databricks Serverless
# Execute este arquivo usando a extensÃ£o Databricks para VS Code

from pyspark.sql import SparkSession

# Inicializa SparkSession (automÃ¡tico no Databricks)
spark = SparkSession.builder.getOrCreate()

# Teste 1: Verificar versÃ£o do Spark
print("=" * 50)
print("ğŸš€ TESTE DE CONEXÃƒO DATABRICKS")
print("=" * 50)
print(f"âœ… Spark Version: {spark.version}")
print(f"âœ… App Name: {spark.sparkContext.appName}")

# Teste 2: Criar um DataFrame simples
data = [
    ("JoÃ£o", "SÃ£o Paulo", 28),
    ("Maria", "Rio de Janeiro", 32),
    ("Pedro", "Belo Horizonte", 25),
    ("Ana", "Curitiba", 30)
]

columns = ["nome", "cidade", "idade"]
df = spark.createDataFrame(data, columns)

print("\nğŸ“Š DataFrame de teste criado:")
df.show()

# Teste 3: OperaÃ§Ãµes bÃ¡sicas
print(f"âœ… Total de registros: {df.count()}")
print(f"âœ… MÃ©dia de idade: {df.agg({'idade': 'avg'}).collect()[0][0]:.1f}")

# Teste 4: Verificar catÃ¡logos disponÃ­veis (Unity Catalog)
print("\nğŸ“ CatÃ¡logos disponÃ­veis:")
try:
    catalogs = spark.sql("SHOW CATALOGS").collect()
    for cat in catalogs:
        print(f"   - {cat[0]}")
except Exception as e:
    print(f"   âš ï¸ Unity Catalog nÃ£o disponÃ­vel: {e}")

print("\n" + "=" * 50)
print("ğŸ‰ CONEXÃƒO FUNCIONANDO PERFEITAMENTE!")
print("=" * 50)
